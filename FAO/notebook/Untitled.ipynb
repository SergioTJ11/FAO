{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5b7b4fdef1d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from operator import add\n",
    "from pyspark.sql import SparkSession\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from tkinter import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local\", \"First App\")\n",
    "sqlCtx = SQLContext(sc)\n",
    "df = sqlCtx.read.json(\"FAOdatabase.json\",  multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.rdd.map(lambda line: line[0]).collect()\n",
    "country_list = sc.parallelize(data, 1).distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.rdd.map(lambda line: (line[0], [line[5]])).reduceByKey(lambda accum, n: accum + n).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.select(*( df.columns[i] for i in [0,5] + [x for x in range(8,61)] )).rdd.map(lambda line: line[0:-1]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc = {}\n",
    "for year in range(1961,2014):\n",
    "    dicc['Y'+ str(year)] = 'sum'\n",
    "\n",
    "prod_years = df.agg(dicc).schema.names\n",
    "prod_sum = df.agg(dicc).rdd.map(lambda line: line[0:54]).collect()[0]\n",
    "\n",
    "Sum = []\n",
    "for i,elt in enumerate(prod_years):\n",
    "    Sum.append([elt[5:9],prod_sum[i]])\n",
    "\n",
    "Sum_ordered = sorted(Sum, key=lambda tup: tup[0])\n",
    "\n",
    "df2 = spark.createDataFrame(Sum_ordered)\n",
    "\n",
    "x = [int(row['_1']) for row in  df2.select('_1').collect()]\n",
    "y = [int(row['_2']) for row in df2.select('_2').collect()]\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "who = df.filter(df.Y1961==112227).rdd.map(lambda line: [line[0]]+[line[5]]).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo = spark \\\n",
    "    .read \\\n",
    "    .format('csv') \\\n",
    "    .options(header='true', inferSchema='true', delimiter=';') \\\n",
    "    .load('./Book1.csv')\n",
    "\n",
    "df_inter = df.join(df_geo, df.Area == df_geo.Country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc = {}\n",
    "for year in range(1961,2014):\n",
    "    dicc['Y'+ str(year)] = 'sum'\n",
    "    \n",
    "prod_by_zones = {}\n",
    "for year in range(1961,2014):\n",
    "    prod_by_zones[str(year)] = []\n",
    "    \n",
    "for zone in ['Asia & Pacific', 'Europe', 'Arab States', 'Africa','South/Latin America', 'Unknown', 'North America']:\n",
    "    \n",
    "    prod_years = df_inter.filter(df_inter.Zone == zone).agg(dicc).schema.names\n",
    "    prod_sum = df_inter.filter(df_inter.Zone == zone).agg(dicc).rdd.map(lambda line: line[0:54]).collect()[0]\n",
    "\n",
    "    Sum = []\n",
    "    for i,elt in enumerate(prod_years):\n",
    "        Sum.append([elt[5:9],prod_sum[i]])\n",
    "\n",
    "    Sum_ordered = sorted(Sum, key=lambda tup: tup[0])\n",
    "\n",
    "    for year in Sum_ordered:\n",
    "        prod_by_zones[year[0]] = prod_by_zones[year[0]] + [(zone,year[1])]\n",
    "\n",
    "AP=[]\n",
    "E=[]\n",
    "AS=[]\n",
    "A=[]\n",
    "SA=[]\n",
    "U=[]\n",
    "NA=[]\n",
    "\n",
    "#years = ['1961', '1962' ,'1963']\n",
    "years = [str(x) for x in range(1961,2014)]\n",
    "\n",
    "for year in years:\n",
    "    AP.append(prod_by_zones[year][0][1])\n",
    "    E.append(prod_by_zones[year][1][1])\n",
    "    AS.append(prod_by_zones[year][2][1])\n",
    "    A.append(prod_by_zones[year][3][1])\n",
    "    SA.append(prod_by_zones[year][4][1])\n",
    "    U.append(prod_by_zones[year][5][1])\n",
    "    NA.append(prod_by_zones[year][6][1])\n",
    "    \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    y=years,\n",
    "    x=AP,\n",
    "    name='Asia & Pacific',\n",
    "    orientation='h',\n",
    "    marker=dict(\n",
    "        color='red',\n",
    "        line=dict(color='black', width=0.25)\n",
    "    )\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    y=years,\n",
    "    x=E,\n",
    "    name='Europe',\n",
    "    orientation='h',\n",
    "    marker=dict(\n",
    "        color='blue',\n",
    "        line=dict(color='black', width=0.25)\n",
    "    )\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    y=years,\n",
    "    x=AS,\n",
    "    name='Arab States',\n",
    "    orientation='h',\n",
    "    marker=dict(\n",
    "        color='green',\n",
    "        line=dict(color='black', width=0.25)\n",
    "    )\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    y=years,\n",
    "    x=A,\n",
    "    name='Africa',\n",
    "    orientation='h',\n",
    "    marker=dict(\n",
    "        color='yellow',\n",
    "        line=dict(color='black', width=0.25)\n",
    "    )\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    y=years,\n",
    "    x=SA,\n",
    "    name='South/Latin America',\n",
    "    orientation='h',\n",
    "    marker=dict(\n",
    "        color='orange',\n",
    "        line=dict(color='black', width=0.25)\n",
    "    )\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    y=years,\n",
    "    x=NA,\n",
    "    name='North America',\n",
    "    orientation='h',\n",
    "    marker=dict(\n",
    "        color='magenta',\n",
    "        line=dict(color='black', width=0.25)\n",
    "    )\n",
    "))\n",
    "\n",
    "fig.update_layout(barmode='stack')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc2 ={'Y2013':'sum'}\n",
    "data = df.rdd.map(lambda line: line[0]).collect()\n",
    "country_list = sc.parallelize(data, 1).distinct().collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = {}\n",
    "for country in country_list:\n",
    "    prod[country] = df.filter(df.Area == country).agg(dicc2).rdd.map(lambda line: line[0]).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in list(prod.items()):\n",
    "    if prod[elt[0]]== None:\n",
    "        prod[elt[0]]=0\n",
    "    \n",
    "coor = df.select(*( df.columns[i] for i in [0,61,62] )).distinct().rdd.map(lambda line: (line[0], line[1], line[2])).collect()\n",
    "df3 = spark.createDataFrame(coor)\n",
    "\n",
    "lati = [int(row['_2']) for row in  df3.select('_2').collect()]\n",
    "long = [int(row['_3']) for row in  df3.select('_3').collect()]\n",
    "name = [row['_1'] for row in  df3.select('_1').collect()]\n",
    "\n",
    "N = {}\n",
    "for i,elt in enumerate(name):\n",
    "    N[elt] = (lati[i],long[i])\n",
    "\n",
    "N1 = list(N.items())\n",
    "N2 = sorted(N1, key=lambda tup: tup[0]) \n",
    "\n",
    "produc = list(prod.values())\n",
    "\n",
    "latitude = []\n",
    "for elt in N2:\n",
    "    latitude.append(elt[1][0])\n",
    "    \n",
    "longitude = []\n",
    "for elt in N2:\n",
    "    longitude.append(elt[1][1])\n",
    "\n",
    "names = []\n",
    "for elt in N2:\n",
    "    names.append(elt[0])\n",
    "\n",
    "fig = go.Figure(data=go.Scattergeo(\n",
    "        lon = longitude,\n",
    "        lat = latitude,\n",
    "        text = names,\n",
    "        mode = 'markers',\n",
    "        marker = dict(\n",
    "            size = 8,\n",
    "            opacity = 0.8,\n",
    "            reversescale = False,\n",
    "            autocolorscale = False,\n",
    "            symbol = 'square',\n",
    "            line = dict(\n",
    "                width=1,\n",
    "                color='rgba(102, 102, 102)'\n",
    "            ),\n",
    "            colorscale = 'Blues',\n",
    "            cmin = 0,\n",
    "            color = produc,\n",
    "            cmax =100000,\n",
    "            colorbar_title=\"Food production (1000 tonnes)\"\n",
    "        )))\n",
    "\n",
    "fig.update_layout(\n",
    "        title = 'Countries 2013',\n",
    "        geo = dict(\n",
    "            scope='world',\n",
    "            #projection_type='albers usa',\n",
    "            showland = True,\n",
    "            landcolor = \"rgb(250, 250, 250)\",\n",
    "            subunitcolor = \"rgb(217, 217, 217)\",\n",
    "            countrycolor = \"rgb(217, 217, 217)\",\n",
    "            countrywidth = 0.5,\n",
    "            subunitwidth = 0.5\n",
    "        ),\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
